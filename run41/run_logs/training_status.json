{
    "Hider1": {
        "checkpoints": [
            {
                "steps": 115492,
                "file_path": "results\\run41\\Hider1\\Hider1-115492.onnx",
                "reward": -0.2457665060008616,
                "creation_time": 1763024425.2847755,
                "auxillary_file_paths": [
                    "results\\run41\\Hider1\\Hider1-115492.pt"
                ]
            },
            {
                "steps": 115967,
                "file_path": "results\\run41\\Hider1\\Hider1-115967.onnx",
                "reward": -0.24796040506000713,
                "creation_time": 1763024435.155107,
                "auxillary_file_paths": [
                    "results\\run41\\Hider1\\Hider1-115967.pt"
                ]
            },
            {
                "steps": 116438,
                "file_path": "results\\run41\\Hider1\\Hider1-116438.onnx",
                "reward": -0.25074396821881695,
                "creation_time": 1763024445.3813133,
                "auxillary_file_paths": [
                    "results\\run41\\Hider1\\Hider1-116438.pt"
                ]
            },
            {
                "steps": 116911,
                "file_path": "results\\run41\\Hider1\\Hider1-116911.onnx",
                "reward": -0.25603774368745397,
                "creation_time": 1763024455.317163,
                "auxillary_file_paths": [
                    "results\\run41\\Hider1\\Hider1-116911.pt"
                ]
            },
            {
                "steps": 117196,
                "file_path": "results\\run41\\Hider1\\Hider1-117196.onnx",
                "reward": -0.25402791496192995,
                "creation_time": 1763024456.542624,
                "auxillary_file_paths": [
                    "results\\run41\\Hider1\\Hider1-117196.pt"
                ]
            }
        ],
        "elo": 953.1241832648855,
        "final_checkpoint": {
            "steps": 117196,
            "file_path": "results\\run41\\Hider1.onnx",
            "reward": -0.25402791496192995,
            "creation_time": 1763024456.542624,
            "auxillary_file_paths": [
                "results\\run41\\Hider1\\Hider1-117196.pt"
            ]
        }
    },
    "Seeker1": {
        "checkpoints": [
            {
                "steps": 130412,
                "file_path": "results\\run41\\Seeker1\\Seeker1-130412.onnx",
                "reward": 0.19660645851925496,
                "creation_time": 1763024429.9464774,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker1\\Seeker1-130412.pt"
                ]
            },
            {
                "steps": 130982,
                "file_path": "results\\run41\\Seeker1\\Seeker1-130982.onnx",
                "reward": 0.19386582122966886,
                "creation_time": 1763024439.997996,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker1\\Seeker1-130982.pt"
                ]
            },
            {
                "steps": 131452,
                "file_path": "results\\run41\\Seeker1\\Seeker1-131452.onnx",
                "reward": 0.19598098926942814,
                "creation_time": 1763024440.8626084,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker1\\Seeker1-131452.pt"
                ]
            },
            {
                "steps": 131926,
                "file_path": "results\\run41\\Seeker1\\Seeker1-131926.onnx",
                "reward": 0.19929560421491568,
                "creation_time": 1763024450.2722645,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker1\\Seeker1-131926.pt"
                ]
            },
            {
                "steps": 132116,
                "file_path": "results\\run41\\Seeker1\\Seeker1-132116.onnx",
                "reward": 0.19716615089708736,
                "creation_time": 1763024456.7164276,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker1\\Seeker1-132116.pt"
                ]
            }
        ],
        "elo": 1503.4422394502542,
        "final_checkpoint": {
            "steps": 132116,
            "file_path": "results\\run41\\Seeker1.onnx",
            "reward": 0.19716615089708736,
            "creation_time": 1763024456.7164276,
            "auxillary_file_paths": [
                "results\\run41\\Seeker1\\Seeker1-132116.pt"
            ]
        }
    },
    "Hider0": {
        "checkpoints": [
            {
                "steps": 121462,
                "file_path": "results\\run41\\Hider0\\Hider0-121462.onnx",
                "reward": -0.29552051913116584,
                "creation_time": 1763024425.599074,
                "auxillary_file_paths": [
                    "results\\run41\\Hider0\\Hider0-121462.pt"
                ]
            },
            {
                "steps": 121937,
                "file_path": "results\\run41\\Hider0\\Hider0-121937.onnx",
                "reward": -0.2943223929061833,
                "creation_time": 1763024435.5599976,
                "auxillary_file_paths": [
                    "results\\run41\\Hider0\\Hider0-121937.pt"
                ]
            },
            {
                "steps": 122410,
                "file_path": "results\\run41\\Hider0\\Hider0-122410.onnx",
                "reward": -0.29812423775394836,
                "creation_time": 1763024445.0577056,
                "auxillary_file_paths": [
                    "results\\run41\\Hider0\\Hider0-122410.pt"
                ]
            },
            {
                "steps": 122976,
                "file_path": "results\\run41\\Hider0\\Hider0-122976.onnx",
                "reward": -0.29918770604838546,
                "creation_time": 1763024455.0842311,
                "auxillary_file_paths": [
                    "results\\run41\\Hider0\\Hider0-122976.pt"
                ]
            },
            {
                "steps": 123356,
                "file_path": "results\\run41\\Hider0\\Hider0-123356.onnx",
                "reward": -0.2978471086918738,
                "creation_time": 1763024456.1555188,
                "auxillary_file_paths": [
                    "results\\run41\\Hider0\\Hider0-123356.pt"
                ]
            }
        ],
        "elo": 1003.6719764726184,
        "final_checkpoint": {
            "steps": 123356,
            "file_path": "results\\run41\\Hider0.onnx",
            "reward": -0.2978471086918738,
            "creation_time": 1763024456.1555188,
            "auxillary_file_paths": [
                "results\\run41\\Hider0\\Hider0-123356.pt"
            ]
        }
    },
    "Seeker0": {
        "checkpoints": [
            {
                "steps": 136949,
                "file_path": "results\\run41\\Seeker0\\Seeker0-136949.onnx",
                "reward": 0.13832659841823633,
                "creation_time": 1763024420.642433,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker0\\Seeker0-136949.pt"
                ]
            },
            {
                "steps": 137421,
                "file_path": "results\\run41\\Seeker0\\Seeker0-137421.onnx",
                "reward": 0.14249383180724157,
                "creation_time": 1763024430.2301521,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker0\\Seeker0-137421.pt"
                ]
            },
            {
                "steps": 137989,
                "file_path": "results\\run41\\Seeker0\\Seeker0-137989.onnx",
                "reward": 0.14605505095470114,
                "creation_time": 1763024440.43698,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker0\\Seeker0-137989.pt"
                ]
            },
            {
                "steps": 138460,
                "file_path": "results\\run41\\Seeker0\\Seeker0-138460.onnx",
                "reward": 0.14856449702022562,
                "creation_time": 1763024449.859866,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker0\\Seeker0-138460.pt"
                ]
            },
            {
                "steps": 138935,
                "file_path": "results\\run41\\Seeker0\\Seeker0-138935.onnx",
                "reward": 0.14831325855857905,
                "creation_time": 1763024456.3507216,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker0\\Seeker0-138935.pt"
                ]
            }
        ],
        "elo": 1422.2895658462458,
        "final_checkpoint": {
            "steps": 138935,
            "file_path": "results\\run41\\Seeker0.onnx",
            "reward": 0.14831325855857905,
            "creation_time": 1763024456.3507216,
            "auxillary_file_paths": [
                "results\\run41\\Seeker0\\Seeker0-138935.pt"
            ]
        }
    },
    "Seeker2": {
        "checkpoints": [
            {
                "steps": 119477,
                "file_path": "results\\run41\\Seeker2\\Seeker2-119477.onnx",
                "reward": 0.045244294469144936,
                "creation_time": 1763024411.0996516,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker2\\Seeker2-119477.pt"
                ]
            },
            {
                "steps": 119949,
                "file_path": "results\\run41\\Seeker2\\Seeker2-119949.onnx",
                "reward": 0.04478049426881486,
                "creation_time": 1763024420.8087466,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker2\\Seeker2-119949.pt"
                ]
            },
            {
                "steps": 120420,
                "file_path": "results\\run41\\Seeker2\\Seeker2-120420.onnx",
                "reward": 0.04762694948000611,
                "creation_time": 1763024440.268811,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker2\\Seeker2-120420.pt"
                ]
            },
            {
                "steps": 120986,
                "file_path": "results\\run41\\Seeker2\\Seeker2-120986.onnx",
                "reward": 0.046304280005204375,
                "creation_time": 1763024450.038676,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker2\\Seeker2-120986.pt"
                ]
            },
            {
                "steps": 121366,
                "file_path": "results\\run41\\Seeker2\\Seeker2-121366.onnx",
                "reward": 0.04869270565680818,
                "creation_time": 1763024455.9924922,
                "auxillary_file_paths": [
                    "results\\run41\\Seeker2\\Seeker2-121366.pt"
                ]
            }
        ],
        "elo": 1470.7718011314857,
        "final_checkpoint": {
            "steps": 121366,
            "file_path": "results\\run41\\Seeker2.onnx",
            "reward": 0.04869270565680818,
            "creation_time": 1763024455.9924922,
            "auxillary_file_paths": [
                "results\\run41\\Seeker2\\Seeker2-121366.pt"
            ]
        }
    },
    "Hider2": {
        "checkpoints": [
            {
                "steps": 98484,
                "file_path": "results\\run41\\Hider2\\Hider2-98484.onnx",
                "reward": -0.2724545530932532,
                "creation_time": 1763024435.3330936,
                "auxillary_file_paths": [
                    "results\\run41\\Hider2\\Hider2-98484.pt"
                ]
            },
            {
                "steps": 98959,
                "file_path": "results\\run41\\Hider2\\Hider2-98959.onnx",
                "reward": -0.2874838772119694,
                "creation_time": 1763024435.9486325,
                "auxillary_file_paths": [
                    "results\\run41\\Hider2\\Hider2-98959.pt"
                ]
            },
            {
                "steps": 99430,
                "file_path": "results\\run41\\Hider2\\Hider2-99430.onnx",
                "reward": -0.2808163334634535,
                "creation_time": 1763024445.556433,
                "auxillary_file_paths": [
                    "results\\run41\\Hider2\\Hider2-99430.pt"
                ]
            },
            {
                "steps": 99998,
                "file_path": "results\\run41\\Hider2\\Hider2-99998.onnx",
                "reward": -0.2870769298527963,
                "creation_time": 1763024455.4870975,
                "auxillary_file_paths": [
                    "results\\run41\\Hider2\\Hider2-99998.pt"
                ]
            },
            {
                "steps": 100188,
                "file_path": "results\\run41\\Hider2\\Hider2-100188.onnx",
                "reward": -0.28792453527380274,
                "creation_time": 1763024455.8428414,
                "auxillary_file_paths": [
                    "results\\run41\\Hider2\\Hider2-100188.pt"
                ]
            }
        ],
        "elo": 908.2099094416353,
        "final_checkpoint": {
            "steps": 100188,
            "file_path": "results\\run41\\Hider2.onnx",
            "reward": -0.28792453527380274,
            "creation_time": 1763024455.8428414,
            "auxillary_file_paths": [
                "results\\run41\\Hider2\\Hider2-100188.pt"
            ]
        }
    },
    "metadata": {
        "stats_format_version": "0.3.0",
        "mlagents_version": "0.30.0",
        "torch_version": "2.6.0+cu124"
    }
}