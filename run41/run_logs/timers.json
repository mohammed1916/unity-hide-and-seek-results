{
    "name": "root",
    "gauges": {
        "Hider2.Policy.Entropy.mean": {
            "value": 3.2073419094085693,
            "min": 3.2046282291412354,
            "max": 3.2106826305389404,
            "count": 306
        },
        "Hider2.Policy.Entropy.sum": {
            "value": 19.244050979614258,
            "min": 19.22776985168457,
            "max": 11500.4921875,
            "count": 306
        },
        "Hider2.Environment.SeekersMeanX.mean": {
            "value": 1.463125766068697,
            "min": -4.122558156649272,
            "max": 3.966179140408834,
            "count": 382
        },
        "Hider2.Environment.SeekersMeanX.sum": {
            "value": 43.89377298206091,
            "min": -20042.195685407554,
            "max": 18801.473597289878,
            "count": 382
        },
        "Hider2.Environment.SeekersMeanZ.mean": {
            "value": 1.5318779244398077,
            "min": -4.552857180436452,
            "max": 3.472813545238404,
            "count": 382
        },
        "Hider2.Environment.SeekersMeanZ.sum": {
            "value": 45.95633773319423,
            "min": -18925.271739052114,
            "max": 14028.211771682661,
            "count": 382
        },
        "Hider2.Environment.HidersMeanX.mean": {
            "value": -0.3591402848561605,
            "min": -5.422173870448023,
            "max": 4.218967477480571,
            "count": 382
        },
        "Hider2.Environment.HidersMeanX.sum": {
            "value": -10.774208545684814,
            "min": -19005.17416312886,
            "max": 17147.864299389767,
            "count": 382
        },
        "Hider2.Environment.HidersMeanZ.mean": {
            "value": -0.9625603119532268,
            "min": -4.564099367832144,
            "max": 3.3857530762751895,
            "count": 382
        },
        "Hider2.Environment.HidersMeanZ.sum": {
            "value": -28.8768093585968,
            "min": -21533.735957487705,
            "max": 17096.572871687436,
            "count": 382
        },
        "Hider2.Environment.EpisodeLength.mean": {
            "value": 94.0,
            "min": 90.5,
            "max": 95.0,
            "count": 142
        },
        "Hider2.Environment.EpisodeLength.sum": {
            "value": 1128.0,
            "min": 93.0,
            "max": 3390.0,
            "count": 142
        },
        "Hider2.Environment.TimeHidden.mean": {
            "value": 0.07444444516052802,
            "min": 0.007777777810891469,
            "max": 0.2397222217793266,
            "count": 135
        },
        "Hider2.Environment.TimeHidden.sum": {
            "value": 0.8933333419263363,
            "min": 0.046666666865348816,
            "max": 2.9400000092573464,
            "count": 135
        },
        "Hider2.Environment.HiderWinRatio.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.08333333333333333,
            "count": 135
        },
        "Hider2.Environment.HiderWinRatio.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 135
        },
        "Hider2.Self-play.ELO.mean": {
            "value": 908.304251025737,
            "min": 908.304251025737,
            "max": 991.2707079998685,
            "count": 124
        },
        "Hider2.Self-play.ELO.sum": {
            "value": 5449.825506154422,
            "min": 910.0899395417636,
            "max": 5947.624247999211,
            "count": 124
        },
        "Hider2.IsTraining.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 542
        },
        "Hider2.IsTraining.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 542
        },
        "Hider2.Step.mean": {
            "value": 100093.0,
            "min": 48872.0,
            "max": 100093.0,
            "count": 541
        },
        "Hider2.Step.sum": {
            "value": 100093.0,
            "min": 48872.0,
            "max": 100093.0,
            "count": 541
        },
        "Hider2.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.34929221868515015,
            "min": -0.6581668853759766,
            "max": 0.20516327023506165,
            "count": 541
        },
        "Hider2.Policy.ExtrinsicValueEstimate.sum": {
            "value": -0.34929221868515015,
            "min": -0.6581668853759766,
            "max": 0.20516327023506165,
            "count": 541
        },
        "Hider2.Policy.CuriosityValueEstimate.mean": {
            "value": -0.08931853622198105,
            "min": -0.2834607660770416,
            "max": 0.3494189977645874,
            "count": 541
        },
        "Hider2.Policy.CuriosityValueEstimate.sum": {
            "value": -0.08931853622198105,
            "min": -0.2834607660770416,
            "max": 0.3494189977645874,
            "count": 541
        },
        "Hider2.Environment.CumulativeReward.mean": {
            "value": -0.6640000343322754,
            "min": -1.192000150680542,
            "max": 1.2000000476837158,
            "count": 541
        },
        "Hider2.Environment.CumulativeReward.sum": {
            "value": -0.6640000343322754,
            "min": -1.192000150680542,
            "max": 1.2000000476837158,
            "count": 541
        },
        "Hider2.Policy.ExtrinsicReward.mean": {
            "value": -2.6640000343322754,
            "min": -3.192000150680542,
            "max": 0.0,
            "count": 541
        },
        "Hider2.Policy.ExtrinsicReward.sum": {
            "value": -2.6640000343322754,
            "min": -3.192000150680542,
            "max": 0.0,
            "count": 541
        },
        "Hider2.Policy.CuriosityReward.mean": {
            "value": 0.44929224252700806,
            "min": 0.0,
            "max": 1.307252287864685,
            "count": 541
        },
        "Hider2.Policy.CuriosityReward.sum": {
            "value": 0.44929224252700806,
            "min": 0.0,
            "max": 1.307252287864685,
            "count": 541
        },
        "Hider2.Losses.PolicyLoss.mean": {
            "value": 0.017080910618897178,
            "min": 0.017080910618897178,
            "max": 0.017080910618897178,
            "count": 1
        },
        "Hider2.Losses.PolicyLoss.sum": {
            "value": 0.017080910618897178,
            "min": 0.017080910618897178,
            "max": 0.017080910618897178,
            "count": 1
        },
        "Hider2.Losses.ValueLoss.mean": {
            "value": 0.12614518988877535,
            "min": 0.12614518988877535,
            "max": 0.12614518988877535,
            "count": 1
        },
        "Hider2.Losses.ValueLoss.sum": {
            "value": 0.12614518988877535,
            "min": 0.12614518988877535,
            "max": 0.12614518988877535,
            "count": 1
        },
        "Hider2.Policy.LearningRate.mean": {
            "value": 0.00029613009012899994,
            "min": 0.00029613009012899994,
            "max": 0.00029613009012899994,
            "count": 1
        },
        "Hider2.Policy.LearningRate.sum": {
            "value": 0.00029613009012899994,
            "min": 0.00029613009012899994,
            "max": 0.00029613009012899994,
            "count": 1
        },
        "Hider2.Policy.Epsilon.mean": {
            "value": 0.10987100000000004,
            "min": 0.10987100000000004,
            "max": 0.10987100000000004,
            "count": 1
        },
        "Hider2.Policy.Epsilon.sum": {
            "value": 0.10987100000000004,
            "min": 0.10987100000000004,
            "max": 0.10987100000000004,
            "count": 1
        },
        "Hider2.Policy.Beta.mean": {
            "value": 0.0005025628999999998,
            "min": 0.0005025628999999998,
            "max": 0.0005025628999999998,
            "count": 1
        },
        "Hider2.Policy.Beta.sum": {
            "value": 0.0005025628999999998,
            "min": 0.0005025628999999998,
            "max": 0.0005025628999999998,
            "count": 1
        },
        "Hider2.Losses.CuriosityForwardLoss.mean": {
            "value": 0.6185679696500301,
            "min": 0.6185679696500301,
            "max": 0.6185679696500301,
            "count": 1
        },
        "Hider2.Losses.CuriosityForwardLoss.sum": {
            "value": 0.6185679696500301,
            "min": 0.6185679696500301,
            "max": 0.6185679696500301,
            "count": 1
        },
        "Hider2.Losses.CuriosityInverseLoss.mean": {
            "value": 4.2355552780628205,
            "min": 4.2355552780628205,
            "max": 4.2355552780628205,
            "count": 1
        },
        "Hider2.Losses.CuriosityInverseLoss.sum": {
            "value": 4.2355552780628205,
            "min": 4.2355552780628205,
            "max": 4.2355552780628205,
            "count": 1
        },
        "Seeker2.Policy.Entropy.mean": {
            "value": 3.210677146911621,
            "min": 3.210069179534912,
            "max": 3.2106845378875732,
            "count": 346
        },
        "Seeker2.Policy.Entropy.sum": {
            "value": 19.264062881469727,
            "min": 19.26376724243164,
            "max": 9554.84765625,
            "count": 346
        },
        "Seeker2.Environment.SeekersMeanX.mean": {
            "value": -1.4136918703715007,
            "min": -3.427124465505282,
            "max": 3.376507172981898,
            "count": 422
        },
        "Seeker2.Environment.SeekersMeanX.sum": {
            "value": -42.41075611114502,
            "min": -18043.752329349634,
            "max": 17796.41016619032,
            "count": 422
        },
        "Seeker2.Environment.SeekersMeanZ.mean": {
            "value": 0.18418811360994974,
            "min": -3.3953638433551774,
            "max": 4.358650995775232,
            "count": 422
        },
        "Seeker2.Environment.SeekersMeanZ.sum": {
            "value": 5.525643408298492,
            "min": -17617.01191566736,
            "max": 18951.66196758533,
            "count": 422
        },
        "Seeker2.Environment.HidersMeanX.mean": {
            "value": 1.1426651440560818,
            "min": -3.5277260343233743,
            "max": 4.804768305520216,
            "count": 422
        },
        "Seeker2.Environment.HidersMeanX.sum": {
            "value": 34.27995432168245,
            "min": -16850.18490887028,
            "max": 17414.416895704693,
            "count": 422
        },
        "Seeker2.Environment.HidersMeanZ.mean": {
            "value": 1.2397200606763363,
            "min": -3.9714063803354898,
            "max": 3.8555064102013907,
            "count": 422
        },
        "Seeker2.Environment.HidersMeanZ.sum": {
            "value": 37.19160182029009,
            "min": -17405.732835085117,
            "max": 17199.061706531968,
            "count": 422
        },
        "Seeker2.Environment.EpisodeLength.mean": {
            "value": 93.5,
            "min": 81.0,
            "max": 98.0,
            "count": 158
        },
        "Seeker2.Environment.EpisodeLength.sum": {
            "value": 1122.0,
            "min": 81.0,
            "max": 2720.0,
            "count": 158
        },
        "Seeker2.Environment.TimeHidden.mean": {
            "value": 0.027222222570950787,
            "min": 0.0,
            "max": 0.36333333142101765,
            "count": 142
        },
        "Seeker2.Environment.TimeHidden.sum": {
            "value": 0.32666667085140944,
            "min": 0.0,
            "max": 2.590000009164214,
            "count": 142
        },
        "Seeker2.Environment.HiderWinRatio.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.08333333333333333,
            "count": 142
        },
        "Seeker2.Environment.HiderWinRatio.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 142
        },
        "Seeker2.Self-play.ELO.mean": {
            "value": 1470.6769470383515,
            "min": 1361.1661796596118,
            "max": 1470.6769470383515,
            "count": 141
        },
        "Seeker2.Self-play.ELO.sum": {
            "value": 8824.061682230109,
            "min": 1369.9687309480298,
            "max": 8824.061682230109,
            "count": 141
        },
        "Seeker2.IsTraining.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 589
        },
        "Seeker2.IsTraining.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 589
        },
        "Seeker2.Step.mean": {
            "value": 121271.0,
            "min": 65559.0,
            "max": 121271.0,
            "count": 588
        },
        "Seeker2.Step.sum": {
            "value": 121271.0,
            "min": 65559.0,
            "max": 121271.0,
            "count": 588
        },
        "Seeker2.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.05673585087060928,
            "min": -0.26787421107292175,
            "max": 0.2404596209526062,
            "count": 588
        },
        "Seeker2.Policy.ExtrinsicValueEstimate.sum": {
            "value": -0.05673585087060928,
            "min": -0.26787421107292175,
            "max": 0.2404596209526062,
            "count": 588
        },
        "Seeker2.Policy.CuriosityValueEstimate.mean": {
            "value": 0.03704455494880676,
            "min": -0.35182783007621765,
            "max": 0.0844135507941246,
            "count": 588
        },
        "Seeker2.Policy.CuriosityValueEstimate.sum": {
            "value": 0.03704455494880676,
            "min": -0.35182783007621765,
            "max": 0.0844135507941246,
            "count": 588
        },
        "Seeker2.Environment.CumulativeReward.mean": {
            "value": 0.7599998712539673,
            "min": -1.2000001668930054,
            "max": 1.191999912261963,
            "count": 588
        },
        "Seeker2.Environment.CumulativeReward.sum": {
            "value": 0.7599998712539673,
            "min": -1.2000001668930054,
            "max": 1.191999912261963,
            "count": 588
        },
        "Seeker2.Policy.ExtrinsicReward.mean": {
            "value": 2.759999990463257,
            "min": -3.200000047683716,
            "max": 3.191999912261963,
            "count": 588
        },
        "Seeker2.Policy.ExtrinsicReward.sum": {
            "value": 2.759999990463257,
            "min": -3.200000047683716,
            "max": 3.191999912261963,
            "count": 588
        },
        "Seeker2.Policy.CuriosityReward.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 588
        },
        "Seeker2.Policy.CuriosityReward.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 588
        },
        "Hider0.Policy.Entropy.mean": {
            "value": 3.2106239795684814,
            "min": 3.210550308227539,
            "max": 3.2106850147247314,
            "count": 355
        },
        "Hider0.Policy.Entropy.sum": {
            "value": 19.263744354248047,
            "min": 19.263301849365234,
            "max": 13388.27734375,
            "count": 355
        },
        "Hider0.Environment.SeekersMeanX.mean": {
            "value": 1.463125766068697,
            "min": -4.122558156649272,
            "max": 3.966179140408834,
            "count": 426
        },
        "Hider0.Environment.SeekersMeanX.sum": {
            "value": 43.89377298206091,
            "min": -15060.596936225687,
            "max": 18768.977509500342,
            "count": 426
        },
        "Hider0.Environment.SeekersMeanZ.mean": {
            "value": 1.5318779244398077,
            "min": -4.552857180436452,
            "max": 3.47282275557518,
            "count": 425
        },
        "Hider0.Environment.SeekersMeanZ.sum": {
            "value": 45.95633773319423,
            "min": -18988.277990864095,
            "max": 14028.211771682661,
            "count": 425
        },
        "Hider0.Environment.HidersMeanX.mean": {
            "value": -0.3591402848561605,
            "min": -5.422173870448023,
            "max": 4.1559604485829675,
            "count": 425
        },
        "Hider0.Environment.HidersMeanX.sum": {
            "value": -10.774208545684814,
            "min": -23839.7873216141,
            "max": 17074.692434999393,
            "count": 425
        },
        "Hider0.Environment.HidersMeanZ.mean": {
            "value": -0.9625603119532268,
            "min": -4.628142776340246,
            "max": 3.3857530762751895,
            "count": 426
        },
        "Hider0.Environment.HidersMeanZ.sum": {
            "value": -28.8768093585968,
            "min": -21398.579516946556,
            "max": 16901.84167542177,
            "count": 426
        },
        "Hider0.Environment.EpisodeLength.mean": {
            "value": 94.0,
            "min": 92.0,
            "max": 95.5,
            "count": 126
        },
        "Hider0.Environment.EpisodeLength.sum": {
            "value": 1128.0,
            "min": 93.0,
            "max": 3876.0,
            "count": 126
        },
        "Hider0.Environment.TimeHidden.mean": {
            "value": 0.07444444516052802,
            "min": 0.010277777987842759,
            "max": 0.2397222217793266,
            "count": 124
        },
        "Hider0.Environment.TimeHidden.sum": {
            "value": 0.8933333419263363,
            "min": 0.1233333358541131,
            "max": 4.133333354257047,
            "count": 124
        },
        "Hider0.Environment.HiderWinRatio.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.08333333333333333,
            "count": 124
        },
        "Hider0.Environment.HiderWinRatio.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 124
        },
        "Hider0.Self-play.ELO.mean": {
            "value": 1003.8306178410586,
            "min": 1003.8306178410586,
            "max": 1067.21593480848,
            "count": 121
        },
        "Hider0.Self-play.ELO.sum": {
            "value": 6022.983707046352,
            "min": 1009.7002058129688,
            "max": 6403.295608850879,
            "count": 121
        },
        "Hider0.IsTraining.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 654
        },
        "Hider0.IsTraining.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 654
        },
        "Hider0.Step.mean": {
            "value": 123261.0,
            "min": 61414.0,
            "max": 123261.0,
            "count": 653
        },
        "Hider0.Step.sum": {
            "value": 123261.0,
            "min": 61414.0,
            "max": 123261.0,
            "count": 653
        },
        "Hider0.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.20437222719192505,
            "min": -0.2784029543399811,
            "max": -0.010458547621965408,
            "count": 653
        },
        "Hider0.Policy.ExtrinsicValueEstimate.sum": {
            "value": -0.20437222719192505,
            "min": -0.2784029543399811,
            "max": -0.010458547621965408,
            "count": 653
        },
        "Hider0.Policy.CuriosityValueEstimate.mean": {
            "value": 0.04398873820900917,
            "min": -0.1727372407913208,
            "max": 0.4455902576446533,
            "count": 653
        },
        "Hider0.Policy.CuriosityValueEstimate.sum": {
            "value": 0.04398873820900917,
            "min": -0.1727372407913208,
            "max": 0.4455902576446533,
            "count": 653
        },
        "Hider0.Environment.CumulativeReward.mean": {
            "value": -0.624000072479248,
            "min": -1.192000150680542,
            "max": 1.2000000476837158,
            "count": 653
        },
        "Hider0.Environment.CumulativeReward.sum": {
            "value": -0.624000072479248,
            "min": -1.192000150680542,
            "max": 1.2000000476837158,
            "count": 653
        },
        "Hider0.Policy.ExtrinsicReward.mean": {
            "value": -2.624000072479248,
            "min": -3.192000389099121,
            "max": 0.0,
            "count": 653
        },
        "Hider0.Policy.ExtrinsicReward.sum": {
            "value": -2.624000072479248,
            "min": -3.192000389099121,
            "max": 0.0,
            "count": 653
        },
        "Hider0.Policy.CuriosityReward.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 653
        },
        "Hider0.Policy.CuriosityReward.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 653
        },
        "Seeker0.Policy.Entropy.mean": {
            "value": 3.189282178878784,
            "min": 3.174182176589966,
            "max": 3.1971797943115234,
            "count": 389
        },
        "Seeker0.Policy.Entropy.sum": {
            "value": 19.135692596435547,
            "min": 19.119985580444336,
            "max": 9480.67578125,
            "count": 389
        },
        "Seeker0.Environment.SeekersMeanX.mean": {
            "value": -1.4136918703715007,
            "min": -3.4271494928333492,
            "max": 2.6222598552703857,
            "count": 471
        },
        "Seeker0.Environment.SeekersMeanX.sum": {
            "value": -42.41075611114502,
            "min": -17769.368100643274,
            "max": 17796.41016619032,
            "count": 471
        },
        "Seeker0.Environment.SeekersMeanZ.mean": {
            "value": 0.18418811360994974,
            "min": -3.4493555150861543,
            "max": 4.386673102110553,
            "count": 471
        },
        "Seeker0.Environment.SeekersMeanZ.sum": {
            "value": 5.525643408298492,
            "min": -17617.01191566736,
            "max": 18951.66196758533,
            "count": 471
        },
        "Seeker0.Environment.HidersMeanX.mean": {
            "value": 1.1426651440560818,
            "min": -3.6398688554763794,
            "max": 4.804768305520216,
            "count": 471
        },
        "Seeker0.Environment.HidersMeanX.sum": {
            "value": 34.27995432168245,
            "min": -16850.18490887028,
            "max": 17376.760917561478,
            "count": 471
        },
        "Seeker0.Environment.HidersMeanZ.mean": {
            "value": 1.2397200606763363,
            "min": -4.548385047250324,
            "max": 4.715281733760127,
            "count": 471
        },
        "Seeker0.Environment.HidersMeanZ.sum": {
            "value": 37.19160182029009,
            "min": -17700.284919585087,
            "max": 17199.061706531968,
            "count": 471
        },
        "Seeker0.Environment.EpisodeLength.mean": {
            "value": 93.5,
            "min": 81.0,
            "max": 98.0,
            "count": 140
        },
        "Seeker0.Environment.EpisodeLength.sum": {
            "value": 1122.0,
            "min": 93.0,
            "max": 2814.0,
            "count": 140
        },
        "Seeker0.Environment.TimeHidden.mean": {
            "value": 0.027222222570950787,
            "min": 0.0,
            "max": 0.36333333142101765,
            "count": 133
        },
        "Seeker0.Environment.TimeHidden.sum": {
            "value": 0.32666667085140944,
            "min": 0.0,
            "max": 2.569999963976443,
            "count": 133
        },
        "Seeker0.Environment.HiderWinRatio.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.16666666666666666,
            "count": 133
        },
        "Seeker0.Environment.HiderWinRatio.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 133
        },
        "Seeker0.Self-play.ELO.mean": {
            "value": 1422.1656372584857,
            "min": 1377.0217531727083,
            "max": 1422.1656372584857,
            "count": 127
        },
        "Seeker0.Self-play.ELO.sum": {
            "value": 8532.993823550914,
            "min": 1377.3665010006907,
            "max": 8532.993823550914,
            "count": 127
        },
        "Seeker0.IsTraining.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 664
        },
        "Seeker0.IsTraining.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 664
        },
        "Seeker0.Step.mean": {
            "value": 138840.0,
            "min": 75951.0,
            "max": 138840.0,
            "count": 663
        },
        "Seeker0.Step.sum": {
            "value": 138840.0,
            "min": 75951.0,
            "max": 138840.0,
            "count": 663
        },
        "Seeker0.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.6337776780128479,
            "min": 0.0004397287266328931,
            "max": 2.7055013179779053,
            "count": 663
        },
        "Seeker0.Policy.ExtrinsicValueEstimate.sum": {
            "value": 0.6337776780128479,
            "min": 0.0004397287266328931,
            "max": 2.7055013179779053,
            "count": 663
        },
        "Seeker0.Policy.CuriosityValueEstimate.mean": {
            "value": 0.004382928367704153,
            "min": -0.09363657981157303,
            "max": 0.697438657283783,
            "count": 663
        },
        "Seeker0.Policy.CuriosityValueEstimate.sum": {
            "value": 0.004382928367704153,
            "min": -0.09363657981157303,
            "max": 0.697438657283783,
            "count": 663
        },
        "Seeker0.Environment.CumulativeReward.mean": {
            "value": 1.1440000534057617,
            "min": -1.2000001668930054,
            "max": 1.192000150680542,
            "count": 663
        },
        "Seeker0.Environment.CumulativeReward.sum": {
            "value": 1.1440000534057617,
            "min": -1.2000001668930054,
            "max": 1.192000150680542,
            "count": 663
        },
        "Seeker0.Policy.ExtrinsicReward.mean": {
            "value": 3.1440000534057617,
            "min": -3.200000047683716,
            "max": 3.192000150680542,
            "count": 663
        },
        "Seeker0.Policy.ExtrinsicReward.sum": {
            "value": 3.1440000534057617,
            "min": -3.200000047683716,
            "max": 3.192000150680542,
            "count": 663
        },
        "Seeker0.Policy.CuriosityReward.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 663
        },
        "Seeker0.Policy.CuriosityReward.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 663
        },
        "Hider1.Policy.Entropy.mean": {
            "value": 3.2068424224853516,
            "min": 3.205101251602173,
            "max": 3.210686683654785,
            "count": 357
        },
        "Hider1.Policy.Entropy.sum": {
            "value": 38.48210906982422,
            "min": 19.230607986450195,
            "max": 11442.650390625,
            "count": 357
        },
        "Hider1.Environment.SeekersMeanX.mean": {
            "value": 1.4625130858272315,
            "min": -4.364370872577031,
            "max": 3.901268970469634,
            "count": 443
        },
        "Hider1.Environment.SeekersMeanX.sum": {
            "value": 87.75078514963388,
            "min": -15060.596936225687,
            "max": 18768.977509500342,
            "count": 443
        },
        "Hider1.Environment.SeekersMeanZ.mean": {
            "value": 1.531102460063994,
            "min": -4.552857180436452,
            "max": 3.47282275557518,
            "count": 444
        },
        "Hider1.Environment.SeekersMeanZ.sum": {
            "value": 91.86614760383964,
            "min": -18925.271739052114,
            "max": 14028.211771682661,
            "count": 444
        },
        "Hider1.Environment.HidersMeanX.mean": {
            "value": -0.3859944740931193,
            "min": -5.421317390379651,
            "max": 3.9118353525797525,
            "count": 445
        },
        "Hider1.Environment.HidersMeanX.sum": {
            "value": -23.159668445587158,
            "min": -15170.018074682797,
            "max": 17031.565806183266,
            "count": 445
        },
        "Hider1.Environment.HidersMeanZ.mean": {
            "value": -0.9723190466562907,
            "min": -4.564099367832144,
            "max": 3.5612738132476807,
            "count": 445
        },
        "Hider1.Environment.HidersMeanZ.sum": {
            "value": -58.33914279937744,
            "min": -21398.579516946556,
            "max": 16889.757521352345,
            "count": 445
        },
        "Hider1.Environment.EpisodeLength.mean": {
            "value": 94.0,
            "min": 90.5,
            "max": 95.5,
            "count": 139
        },
        "Hider1.Environment.EpisodeLength.sum": {
            "value": 1128.0,
            "min": 93.0,
            "max": 3390.0,
            "count": 139
        },
        "Hider1.Environment.TimeHidden.mean": {
            "value": 0.07444444516052802,
            "min": 0.0027777779226501784,
            "max": 0.2397222217793266,
            "count": 135
        },
        "Hider1.Environment.TimeHidden.sum": {
            "value": 0.8933333419263363,
            "min": 0.01666666753590107,
            "max": 2.973333323840052,
            "count": 135
        },
        "Hider1.Environment.HiderWinRatio.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.08333333333333333,
            "count": 135
        },
        "Hider1.Environment.HiderWinRatio.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 135
        },
        "Hider1.Self-play.ELO.mean": {
            "value": 953.2446875833085,
            "min": 953.2446875833085,
            "max": 999.3413461769242,
            "count": 128
        },
        "Hider1.Self-play.ELO.sum": {
            "value": 5719.468125499851,
            "min": 953.7080897773538,
            "max": 19280.93600644445,
            "count": 128
        },
        "Hider1.IsTraining.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 652
        },
        "Hider1.IsTraining.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 652
        },
        "Hider1.Step.mean": {
            "value": 117101.0,
            "min": 55412.0,
            "max": 117101.0,
            "count": 651
        },
        "Hider1.Step.sum": {
            "value": 117101.0,
            "min": 55412.0,
            "max": 117101.0,
            "count": 651
        },
        "Hider1.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.4970373511314392,
            "min": -0.6637709736824036,
            "max": 0.06766855716705322,
            "count": 651
        },
        "Hider1.Policy.ExtrinsicValueEstimate.sum": {
            "value": -0.4970373511314392,
            "min": -0.6637709736824036,
            "max": 0.06766855716705322,
            "count": 651
        },
        "Hider1.Policy.CuriosityValueEstimate.mean": {
            "value": -0.19118449091911316,
            "min": -0.4934934973716736,
            "max": 0.12137432396411896,
            "count": 651
        },
        "Hider1.Policy.CuriosityValueEstimate.sum": {
            "value": -0.19118449091911316,
            "min": -0.4934934973716736,
            "max": 0.12137432396411896,
            "count": 651
        },
        "Hider1.Environment.CumulativeReward.mean": {
            "value": -0.8960000872612,
            "min": -1.192000150680542,
            "max": 1.2000000476837158,
            "count": 651
        },
        "Hider1.Environment.CumulativeReward.sum": {
            "value": -0.8960000872612,
            "min": -1.192000150680542,
            "max": 1.2000000476837158,
            "count": 651
        },
        "Hider1.Policy.ExtrinsicReward.mean": {
            "value": -2.8959999084472656,
            "min": -3.192000389099121,
            "max": 0.0,
            "count": 651
        },
        "Hider1.Policy.ExtrinsicReward.sum": {
            "value": -2.8959999084472656,
            "min": -3.192000389099121,
            "max": 0.0,
            "count": 651
        },
        "Hider1.Policy.CuriosityReward.mean": {
            "value": 0.36730241775512695,
            "min": 0.0,
            "max": 1.1562907695770264,
            "count": 651
        },
        "Hider1.Policy.CuriosityReward.sum": {
            "value": 0.36730241775512695,
            "min": 0.0,
            "max": 1.1562907695770264,
            "count": 651
        },
        "Hider1.Losses.PolicyLoss.mean": {
            "value": 0.016603002831488994,
            "min": 0.016603002831488994,
            "max": 0.016603002831488994,
            "count": 1
        },
        "Hider1.Losses.PolicyLoss.sum": {
            "value": 0.016603002831488994,
            "min": 0.016603002831488994,
            "max": 0.016603002831488994,
            "count": 1
        },
        "Hider1.Losses.ValueLoss.mean": {
            "value": 0.11562019329518079,
            "min": 0.11562019329518079,
            "max": 0.11562019329518079,
            "count": 1
        },
        "Hider1.Losses.ValueLoss.sum": {
            "value": 0.11562019329518079,
            "min": 0.11562019329518079,
            "max": 0.11562019329518079,
            "count": 1
        },
        "Hider1.Policy.LearningRate.mean": {
            "value": 9.56700968109999e-05,
            "min": 9.56700968109999e-05,
            "max": 9.56700968109999e-05,
            "count": 1
        },
        "Hider1.Policy.LearningRate.sum": {
            "value": 9.56700968109999e-05,
            "min": 9.56700968109999e-05,
            "max": 9.56700968109999e-05,
            "count": 1
        },
        "Hider1.Policy.Epsilon.mean": {
            "value": 0.10318899999999999,
            "min": 0.10318899999999999,
            "max": 0.10318899999999999,
            "count": 1
        },
        "Hider1.Policy.Epsilon.sum": {
            "value": 0.10318899999999999,
            "min": 0.10318899999999999,
            "max": 0.10318899999999999,
            "count": 1
        },
        "Hider1.Policy.Beta.mean": {
            "value": 0.0001691310999999999,
            "min": 0.0001691310999999999,
            "max": 0.0001691310999999999,
            "count": 1
        },
        "Hider1.Policy.Beta.sum": {
            "value": 0.0001691310999999999,
            "min": 0.0001691310999999999,
            "max": 0.0001691310999999999,
            "count": 1
        },
        "Hider1.Losses.CuriosityForwardLoss.mean": {
            "value": 0.6405728860199451,
            "min": 0.6405728860199451,
            "max": 0.6405728860199451,
            "count": 1
        },
        "Hider1.Losses.CuriosityForwardLoss.sum": {
            "value": 0.6405728860199451,
            "min": 0.6405728860199451,
            "max": 0.6405728860199451,
            "count": 1
        },
        "Hider1.Losses.CuriosityInverseLoss.mean": {
            "value": 4.168132064342498,
            "min": 4.168132064342498,
            "max": 4.168132064342498,
            "count": 1
        },
        "Hider1.Losses.CuriosityInverseLoss.sum": {
            "value": 4.168132064342498,
            "min": 4.168132064342498,
            "max": 4.168132064342498,
            "count": 1
        },
        "Seeker1.Policy.Entropy.mean": {
            "value": 3.197779655456543,
            "min": 3.1447787284851074,
            "max": 3.199875593185425,
            "count": 372
        },
        "Seeker1.Policy.Entropy.sum": {
            "value": 38.373355865478516,
            "min": 19.147743225097656,
            "max": 9494.470703125,
            "count": 372
        },
        "Seeker1.Environment.SeekersMeanX.mean": {
            "value": -1.414685861269633,
            "min": -3.5817513714234033,
            "max": 3.376507172981898,
            "count": 450
        },
        "Seeker1.Environment.SeekersMeanX.sum": {
            "value": -84.88115167617798,
            "min": -17769.368100643274,
            "max": 17847.614184187107,
            "count": 450
        },
        "Seeker1.Environment.SeekersMeanZ.mean": {
            "value": 0.184135107199351,
            "min": -3.4416255452010946,
            "max": 4.386673102110553,
            "count": 450
        },
        "Seeker1.Environment.SeekersMeanZ.sum": {
            "value": 11.04810643196106,
            "min": -17639.594654782122,
            "max": 19008.398524368647,
            "count": 450
        },
        "Seeker1.Environment.HidersMeanX.mean": {
            "value": 1.1209155484219082,
            "min": -3.4425137996673585,
            "max": 4.2409029139412775,
            "count": 450
        },
        "Seeker1.Environment.HidersMeanX.sum": {
            "value": 67.25493290531449,
            "min": -16843.227642956794,
            "max": 17376.760917561478,
            "count": 450
        },
        "Seeker1.Environment.HidersMeanZ.mean": {
            "value": 1.1435337930296858,
            "min": -3.8767239938179654,
            "max": 4.717116594314575,
            "count": 450
        },
        "Seeker1.Environment.HidersMeanZ.sum": {
            "value": 68.61202758178115,
            "min": -17574.92308189998,
            "max": 17199.061706531968,
            "count": 450
        },
        "Seeker1.Environment.EpisodeLength.mean": {
            "value": 93.5,
            "min": 81.0,
            "max": 98.0,
            "count": 149
        },
        "Seeker1.Environment.EpisodeLength.sum": {
            "value": 1122.0,
            "min": 94.0,
            "max": 2440.0,
            "count": 149
        },
        "Seeker1.Environment.TimeHidden.mean": {
            "value": 0.027222222570950787,
            "min": 0.0,
            "max": 0.36333333142101765,
            "count": 137
        },
        "Seeker1.Environment.TimeHidden.sum": {
            "value": 0.32666667085140944,
            "min": 0.0,
            "max": 2.203333373647183,
            "count": 137
        },
        "Seeker1.Environment.HiderWinRatio.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.16666666666666666,
            "count": 137
        },
        "Seeker1.Environment.HiderWinRatio.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 137
        },
        "Seeker1.Self-play.ELO.mean": {
            "value": 1503.3629425764555,
            "min": 1477.2883365273785,
            "max": 1503.3629425764555,
            "count": 137
        },
        "Seeker1.Self-play.ELO.sum": {
            "value": 9020.177655458732,
            "min": 1479.3645206019967,
            "max": 9020.177655458732,
            "count": 137
        },
        "Seeker1.IsTraining.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 638
        },
        "Seeker1.IsTraining.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 638
        },
        "Seeker1.Step.mean": {
            "value": 132021.0,
            "min": 71680.0,
            "max": 132021.0,
            "count": 637
        },
        "Seeker1.Step.sum": {
            "value": 132021.0,
            "min": 71680.0,
            "max": 132021.0,
            "count": 637
        },
        "Seeker1.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.4621341824531555,
            "min": 0.172455832362175,
            "max": 2.942009449005127,
            "count": 637
        },
        "Seeker1.Policy.ExtrinsicValueEstimate.sum": {
            "value": 0.4621341824531555,
            "min": 0.172455832362175,
            "max": 2.942009449005127,
            "count": 637
        },
        "Seeker1.Policy.CuriosityValueEstimate.mean": {
            "value": -0.05965891852974892,
            "min": -0.10051067173480988,
            "max": 0.5883587598800659,
            "count": 637
        },
        "Seeker1.Policy.CuriosityValueEstimate.sum": {
            "value": -0.05965891852974892,
            "min": -0.10051067173480988,
            "max": 0.5883587598800659,
            "count": 637
        },
        "Seeker1.Environment.CumulativeReward.mean": {
            "value": -0.6720000505447388,
            "min": -1.2000001668930054,
            "max": 1.192000150680542,
            "count": 637
        },
        "Seeker1.Environment.CumulativeReward.sum": {
            "value": -0.6720000505447388,
            "min": -1.2000001668930054,
            "max": 1.192000150680542,
            "count": 637
        },
        "Seeker1.Policy.ExtrinsicReward.mean": {
            "value": 1.3280000686645508,
            "min": 0.0,
            "max": 3.192000389099121,
            "count": 637
        },
        "Seeker1.Policy.ExtrinsicReward.sum": {
            "value": 1.3280000686645508,
            "min": 0.0,
            "max": 3.192000389099121,
            "count": 637
        },
        "Seeker1.Policy.CuriosityReward.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 637
        },
        "Seeker1.Policy.CuriosityReward.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 637
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1763022627",
        "python_version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\BBBS-AI-01\\.conda\\envs\\py10\\Scripts\\mlagents-learn config/ppo_trainer_ma_competitive_modular.yaml --run-id=run41 --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.6.0+cu124",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1763024456"
    },
    "total": 1829.1729609999984,
    "count": 1,
    "self": 0.04439719999936642,
    "children": {
        "run_training.setup": {
            "total": 0.10022060000119382,
            "count": 1,
            "self": 0.10022060000119382
        },
        "TrainerController.start_learning": {
            "total": 1829.0283431999978,
            "count": 1,
            "self": 0.9161898002876114,
            "children": {
                "TrainerController._reset_env": {
                    "total": 21.29233700001896,
                    "count": 526,
                    "self": 21.29233700001896
                },
                "TrainerController.advance": {
                    "total": 1805.7748500996913,
                    "count": 23075,
                    "self": 0.3671974997087091,
                    "children": {
                        "env_step": {
                            "total": 1805.4076525999826,
                            "count": 23075,
                            "self": 557.7288932002102,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1247.3670586000353,
                                    "count": 23075,
                                    "self": 8.604222600495632,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1238.7628359995397,
                                            "count": 137430,
                                            "self": 1238.7628359995397
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.311700799737082,
                                    "count": 23075,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1816.4428460999661,
                                            "count": 23075,
                                            "is_parallel": true,
                                            "self": 1415.5691475000312,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 1.792406700027641,
                                                    "count": 3150,
                                                    "is_parallel": true,
                                                    "self": 0.4909595996632561,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 1.3014471003643848,
                                                            "count": 25200,
                                                            "is_parallel": true,
                                                            "self": 1.3014471003643848
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 399.0812918999072,
                                                    "count": 23075,
                                                    "is_parallel": true,
                                                    "self": 42.49251169970012,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 12.412948800327285,
                                                            "count": 23075,
                                                            "is_parallel": true,
                                                            "self": 12.412948800327285
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 268.1634032999318,
                                                            "count": 23075,
                                                            "is_parallel": true,
                                                            "self": 268.1634032999318
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 76.01242809994801,
                                                            "count": 138450,
                                                            "is_parallel": true,
                                                            "self": 20.434808999980305,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 55.577619099967706,
                                                                    "count": 1107600,
                                                                    "is_parallel": true,
                                                                    "self": 55.577619099967706
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 0.00012000000060652383,
                    "count": 1,
                    "self": 0.00012000000060652383,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 10885.812727500426,
                                    "count": 619597,
                                    "is_parallel": true,
                                    "self": 84.19835540105669,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 10658.13988649937,
                                            "count": 619597,
                                            "is_parallel": true,
                                            "self": 10345.757827599316,
                                            "children": {
                                                "RLTrainer._checkpoint": {
                                                    "total": 312.3820589000534,
                                                    "count": 710,
                                                    "is_parallel": true,
                                                    "self": 312.3820589000534
                                                }
                                            }
                                        },
                                        "_update_policy": {
                                            "total": 143.47448559999975,
                                            "count": 2,
                                            "is_parallel": true,
                                            "self": 106.734073500058,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 36.74041209994175,
                                                    "count": 400,
                                                    "is_parallel": true,
                                                    "self": 36.74041209994175
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 1.0448462999993353,
                    "count": 1,
                    "self": 0.013819300002069212,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 1.031026999997266,
                            "count": 6,
                            "self": 1.031026999997266
                        }
                    }
                }
            }
        }
    }
}